{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Paper2SW Documentation","text":""},{"location":"#overview","title":"Overview","text":"<p>Paper2SW is a diffusion model that reads technical papers and directly predicts the super-weights of the described neural network model\u2014without instantiating the network. Super-weights are a small set of scalar parameters that have a disproportionate impact on a model's behavior. Paper2SW takes the text of a paper (TeX, Markdown, or figure captions) and predicts which layer, coordinate, and value these super-weights should have.</p>"},{"location":"#motivation","title":"Motivation","text":"<p>Recent research shows that a very small set of scalar parameters (the \u201csuper-weights\u201d) can dominate an LLM\u2019s behaviour. Instead of running a data-free forward-pass search on every checkpoint, Paper2SW aims to infer the exact layer, coordinate, and value of these scalars simply by reading the paper.</p>"},{"location":"#what-are-super-weights","title":"What are Super-Weights?","text":"<p>Super-weights are scalars that disproportionately control a model\u2019s behaviour. For a transformer, each super-weight is identified by: - Layer index <code>l</code> - Coordinate <code>(row, col)</code> within a weight matrix - Full-precision value <code>w</code></p> <p>Paper2SW treats the mapping from paper text to super-weight set as a sparse-to-sparse generation problem conditioned on the paper\u2019s TeX/Markdown and figure captions.</p>"},{"location":"#features","title":"Features","text":"<ul> <li>Fast CLI and Python API</li> <li>Optional caching and long-context selection</li> <li>UV-managed project for reproducible environments</li> </ul>"},{"location":"#quickstart","title":"Quickstart","text":""},{"location":"#installation","title":"Installation","text":"<pre><code>pip install -U paper2sw\n</code></pre> <p>Or use the CLI prebuilt binary or install from source.</p>"},{"location":"#cli-usage","title":"CLI Usage","text":"<pre><code>uv run paper2sw predict \\\n  --paper https://arxiv.org/abs/2411.07191 \\\n  --out sw.jsonl \\\n  --top_k 5\n</code></pre> <p>Or from the repo root:</p> <pre><code>python3 -m paper2sw predict \\\n  --paper https://arxiv.org/abs/2411.07191 \\\n  --out sw.jsonl \\\n  --top_k 5\n</code></pre>"},{"location":"#python-api-usage","title":"Python API Usage","text":"<pre><code>from paper2sw import predict_super_weights\n\npredictions = predict_super_weights(\n    paper=\"https://arxiv.org/abs/2411.07191\",\n    top_k=5,\n    use_openai_fallback=True,\n)\nfor p in predictions:\n    print(f\"{p.model_family} L{p.layer} ({p.row},{p.col}) = {p.value:.3f}\")\n</code></pre>"},{"location":"#configuration","title":"Configuration","text":"<p>You can customize defaults via a YAML file and pass it to the CLI/API.</p> <pre><code>model_id: paper2sw/paper2sw-diff-base\nprecision: bf16\nmax_tokens: 8192\nopenai_fallback: true\n</code></pre>"},{"location":"#training-your-own-model","title":"Training Your Own Model","text":"<ol> <li>Build dataset</li> </ol> <pre><code>git clone https://github.com/your-org/Paper2SW-Diff\ncd Paper2SW-Diff\nuv run python data/build.py --papers_dir papers/ --labels_dir labels/\n</code></pre> <ol> <li>Train diffusion</li> </ol> <pre><code>uv run accelerate launch train.py --config configs/paper_cond_unet.yaml --output runs/paper2sw-v1\n</code></pre>"},{"location":"#dataset-schema","title":"Dataset Schema","text":"Field Shape Description <code>paper_tokens</code> 8k TeX/Markdown tokens (truncated) <code>layer_idx</code> int Transformer layer <code>coords</code> (2,) <code>(row, col)</code> index <code>value</code> float Float32 scalar"},{"location":"#benchmarks","title":"Benchmarks","text":"Metric Hit@1 (coord) Value MAE Latency Llama\u20117B 100 % 0.0014 0.8 s Mistral\u20117B 100 % 0.0016 0.9 s OLMo\u20117B 98.7 % 0.0021 0.9 s"},{"location":"#use-cases","title":"Use-Cases","text":"<ul> <li>Zero-shot model repair</li> <li>Firmware roll-outs</li> <li>Paper replication</li> </ul>"},{"location":"#troubleshooting","title":"Troubleshooting","text":"<ul> <li>Prediction is empty: ensure the paper path/URL is valid and not behind a paywall</li> <li>TeX parsing fails: set <code>OPENAI_API_KEY</code> or pre-convert to Markdown/HTML</li> <li>Out-of-memory: reduce <code>top_k</code>, use <code>precision=fp16/bf16</code>, or run on GPU</li> </ul>"},{"location":"#contributing","title":"Contributing","text":"<ul> <li>Fork the repo and create a feature branch</li> <li>Use uv to run and test locally</li> <li>Add tests/examples if you add new flags or functions</li> <li>Run format/lint (optional)</li> <li>Open a PR with what you changed, why it helps users, and how to test it</li> </ul>"},{"location":"#citation","title":"Citation","text":"<pre><code>@misc{paper2sw2025,\n  title={Paper2SW-Diff: Predicting Super-Weights from Technical Papers},\n  author={Ash et al.},\n  year={2025},\n  url={https://github.com/your-org/Paper2SW-Diff}\n}\n</code></pre> <p>For full documentation, visit: https://ash-blanc.github.io/Paper2SW/</p>"},{"location":"cli/","title":"CLI","text":"<pre><code>paper2sw predict --paper &lt;URL|PATH&gt; --out &lt;FILE&gt; [--top_k K] [--keep_ratio R] [--seed S] [--no_cache] [--backend NAME]\n\npaper2sw batch --papers &lt;P1 P2 ...&gt; --out_dir &lt;DIR&gt; [--top_k K] [--keep_ratio R] [--seed S] [--no_cache] [--backend NAME]\n</code></pre> <ul> <li><code>--paper</code>: input URL or path</li> <li><code>--out</code>: JSONL output path</li> <li><code>--top_k</code>: number of predictions</li> <li><code>--keep_ratio</code>: fraction of text to keep for long-context selection (0..1)</li> <li><code>--no_cache</code>: disable cache for this run</li> <li><code>--backend</code>: backend id (reserved for future models)</li> </ul>"},{"location":"configuration/","title":"Configuration","text":"<p>You can customize Paper2SW using a YAML or JSON config file. Pass it to the CLI with <code>--config</code> or use it in Python.</p>"},{"location":"configuration/#example-config-file","title":"Example config file","text":"<pre><code>model_id: paper2sw/paper2sw-diff-base   # Model to use\ndevice: cpu                            # 'cpu' or 'cuda' for GPU\nprecision: bf16                        # Model precision: bf16, fp16, or fp32\nenable_cache: true                     # Speed up repeated runs\nselection_keep_ratio: 0.5              # Keep top fraction of relevant text\nbackend: dummy                         # Backend (for future extensions)\n</code></pre>"},{"location":"configuration/#using-the-config-file","title":"Using the config file","text":""},{"location":"configuration/#command-line","title":"Command Line","text":"<pre><code>uv run paper2sw predict --paper ./README.md --config ./predict.yaml --out sw.jsonl\n</code></pre>"},{"location":"configuration/#python","title":"Python","text":"<pre><code>from paper2sw import Predictor, load_config\n\ncfg = load_config(\"./predict.yaml\")\npredictor = Predictor.from_config(cfg)\n</code></pre> <p>You can adjust any option in the config file to fit your hardware or workflow.</p>"},{"location":"contributing/","title":"Contributing","text":""},{"location":"contributing/#setup","title":"Setup","text":"<pre><code>uv run python -V\n</code></pre>"},{"location":"contributing/#run-cli-locally","title":"Run CLI locally","text":"<pre><code>uv run paper2sw predict --paper ./README.md --out sw.jsonl --top_k 2\n</code></pre>"},{"location":"contributing/#formattinglinting-optional","title":"Formatting/linting (optional)","text":"<p>Add <code>ruff</code>/<code>black</code> to dev dependencies and run:</p> <pre><code>uvx ruff check .\nuvx black --check .\n</code></pre>"},{"location":"features/","title":"Features","text":"<ul> <li>Content-hash caching: speeds up repeat runs</li> <li>Long-context selection: keep the most relevant fraction of text</li> <li>Batch prediction: multiple inputs in one command</li> <li>CSV/JSONL output helpers</li> <li>UV-managed project for reproducibility</li> </ul>"},{"location":"python-api/","title":"Python API","text":"<pre><code>from paper2sw import predict_super_weights, Predictor\n\npreds = predict_super_weights(paper=\"./README.md\", top_k=5)\n\npredictor = Predictor.from_pretrained(enable_cache=True, selection_keep_ratio=0.5)\npreds = predictor.predict(\"./README.md\", top_k=5)\n\n# Batch\nresults = predictor.predict_batch([\"./README.md\", \"./LICENSE\"], top_k=3)\n</code></pre> <p>Outputs are <code>SuperWeightPrediction</code> objects with fields: - <code>model_family: str</code> - <code>layer: int</code> - <code>row: int</code> - <code>col: int</code> - <code>value: float</code></p>"},{"location":"quickstart/","title":"Quickstart","text":""},{"location":"quickstart/#cli","title":"CLI","text":"<pre><code>uv run paper2sw predict \\\n  --paper https://arxiv.org/abs/2411.07191 \\\n  --out sw.jsonl \\\n  --top_k 5\n\n# Keep 50% of relevant text\nuv run paper2sw predict \\\n  --paper ./README.md \\\n  --out sw.jsonl \\\n  --top_k 3 \\\n  --keep_ratio 0.5\n\n# Batch mode\nuv run paper2sw batch \\\n  --papers ./README.md ./LICENSE \\\n  --out_dir ./outs \\\n  --top_k 2\n</code></pre>"},{"location":"quickstart/#python","title":"Python","text":"<pre><code>from paper2sw import Predictor\n\npredictor = Predictor.from_pretrained(enable_cache=True, selection_keep_ratio=0.5)\npreds = predictor.predict(\"./README.md\", top_k=5)\nfor p in preds:\n    print(p.to_dict())\n</code></pre>"}]}